{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib\n",
    "matplotlib.use('Qt5agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "distortion_correction_file = Path(\"./distortion_correction_pickle.p\")\n",
    "if distortion_correction_file.is_file():\n",
    "    print('Distortion correction file already created')\n",
    "else:\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob('./camera_cal/calibration*.jpg')\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "            cv2.imshow('img',img)\n",
    "            cv2.waitKey(500)\n",
    "\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Apply distortion correction to test images and save the camera calibration result for later use\n",
    "Use object points and image points to calculate distortion coefficients, and test undistortion on an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "# Make a list of test images set 1\n",
    "test_images_1 = glob.glob('./test_images/test*.jpg')\n",
    "# Make a list of test images set 2\n",
    "test_images_2 = glob.glob('./test_images/straight_lines*.jpg')\n",
    "# Combine the test images set 1 and 2\n",
    "test_images = test_images_1 + test_images_2\n",
    "\n",
    "# Test undistortion on an image\n",
    "test_img_path = './test_images/straight_lines1.jpg'\n",
    "img = cv2.imread(test_img_path)\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "print('image size is {}'.format(img_size))\n",
    "\n",
    "# check if we already created the calibration file with coefficients\n",
    "if distortion_correction_file.is_file():\n",
    "    # load the coefficients to undistort the camera image\n",
    "    with open('./distortion_correction_pickle.p', mode='rb') as f:\n",
    "        calibration_file = pickle.load(f)\n",
    "        mtx, dist = calibration_file['mtx'], calibration_file['dist']\n",
    "else:\n",
    "    print('Calibration does not exist. Please run the cell above to create it first.')\n",
    "    # Do camera calibration given object points and image points\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "    # Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "    dist_pickle = {}\n",
    "    dist_pickle[\"mtx\"] = mtx\n",
    "    dist_pickle[\"dist\"] = dist\n",
    "    pickle.dump( dist_pickle, open( './distortion_correction_pickle.p', 'wb' ) )\n",
    "\n",
    "# apply distortion correction to the camera calibration image\n",
    "filename = './camera_cal/calibration1.jpg'\n",
    "img = cv2.imread(filename)\n",
    "dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "# Process the file name for saving to a different directory\n",
    "filename = filename.replace('./camera_cal/', '')\n",
    "undistorted_filename = './output_images/' + 'undist_' + filename\n",
    "cv2.imwrite(undistorted_filename, dst)\n",
    "# Convert to RGB color space\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "dst = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=25)\n",
    "ax2.imshow(dst)\n",
    "ax2.set_title('Undistorted Image', fontsize=25)    \n",
    "\n",
    "# apply distortion correction to the test images\n",
    "for filename in test_images:\n",
    "    img = cv2.imread(filename)\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    # Process the file name for saving to a different directory\n",
    "    filename = filename.replace('./test_images/', '')\n",
    "    undistorted_filename = './output_images/' + 'undist_' + filename\n",
    "    cv2.imwrite(undistorted_filename, dst)\n",
    "    # Convert to RGB color space\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    dst = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
    "    # Visualize undistortion\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=25)\n",
    "    ax2.imshow(dst)\n",
    "    ax2.set_title('Undistorted Image', fontsize=25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Apply the perspective transform to convert the binary image to a birds-eye view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from skimage import img_as_uint\n",
    "from skimage import io\n",
    "\n",
    "# Define a function that applies Sobel x or y, \n",
    "# then takes an absolute value and applies a threshold.\n",
    "# Note: calling your function with orient='x', thresh_min=5, thresh_max=100\n",
    "# should produce output like the example image shown above this quiz.\n",
    "def abs_sobel_thresh(img, orient='x', thresh=(20, 100), sobel_kernel=3):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)    \n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    grad_binary = np.zeros_like(scaled_sobel)\n",
    "    grad_binary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "\n",
    "    # 6) Return this mask as your binary_output image\n",
    "\n",
    "    return grad_binary\n",
    "\n",
    "# def pipeline(img, h_thresh = (14, 24), s_thresh=(75, 255), \n",
    "#              white_h_thresh = (0, 179), white_s_thresh=(1, 25), white_v_thresh = (200, 255), \n",
    "#              sx_thresh=(20, 100), sy_thresh=(20, 100),\n",
    "#              dir_thresh = (25,75), \n",
    "#              sobel_kernel=3):\n",
    "#     img = np.copy(img)\n",
    "#     # Convert to HSV color space and separate the V channel\n",
    "#     hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV).astype(np.float)\n",
    "#     h_channel = hsv[:,:,0]\n",
    "#     s_channel = hsv[:,:,1]\n",
    "#     v_channel = hsv[:,:,2]\n",
    "\n",
    "#     # Threshold x gradient\n",
    "#     sxbinary = abs_sobel_thresh(img, orient='x', thresh=(20, 100))\n",
    "            \n",
    "#     # Threshold the hue channel\n",
    "#     # yellow hue\n",
    "#     h_binary = np.zeros_like(h_channel)\n",
    "#     h_binary[(h_channel >= h_thresh[0]) & (h_channel <= h_thresh[1])] = 1\n",
    "#     # white hue (basically anything)\n",
    "#     white_h_binary = np.zeros_like(h_channel)\n",
    "#     white_h_binary[(h_channel >= white_h_thresh[0]) & (h_channel <= white_h_thresh[1])] = 1 \n",
    "    \n",
    "#     # Threshold saturation channel\n",
    "#     # yellow saturation\n",
    "#     s_binary = np.zeros_like(s_channel)\n",
    "#     s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "#     # white saturation (very low)\n",
    "#     white_s_binary = np.zeros_like(s_channel)\n",
    "#     white_s_binary[(s_channel >= white_s_thresh[0]) & (s_channel <= white_s_thresh[1])] = 1\n",
    "    \n",
    "#     # Threshold v channel\n",
    "#     white_v_binary = np.zeros_like(v_channel)\n",
    "#     white_v_binary[(v_channel >= white_v_thresh[0]) & (v_channel <= white_v_thresh[1])] = 1    \n",
    "    \n",
    "#     combined_output = np.zeros_like(s_channel)\n",
    "#     binary_output1 = np.zeros_like(s_channel)\n",
    "#     binary_output2 = np.zeros_like(s_channel)\n",
    "#     binary_output3 = np.zeros_like(s_channel)\n",
    "    \n",
    "#     binary_output1[((sxbinary ==1) | (s_binary == 1)) & (h_binary==1)] = 1 # yellow line\n",
    "#     binary_output2[(sxbinary == 1) & ((white_s_binary == 1) & (white_h_binary==1))] = 1 #  white line 1\n",
    "#     binary_output3[(sxbinary == 1) | ((white_v_binary == 1) & (white_s_binary == 1) & (white_h_binary==1))] = 1 # white line 2\n",
    "    \n",
    "#     combined_output[(binary_output1 == 1) | (binary_output2 == 1) | (binary_output3 == 1)] = 1\n",
    "\n",
    "#     # Stack each channel to visualize the effect of each output\n",
    "#     color_binary = np.dstack((binary_output1, binary_output2, binary_output3))\n",
    "#     #return b+w binary and color_binary\n",
    "#     return combined_output, color_binary\n",
    "\n",
    "# Read in a test image\n",
    "test_img = './test_images/test5.jpg'\n",
    "# test_img = './test_images/straight_lines1.jpg'\n",
    "# test_img = './test_images/challenge.jpg'\n",
    "# test_img = './test_images/cement2.jpg'\n",
    "# test_img = './test_images/FirstFrame.jpg'\n",
    "\n",
    "image = mpimg.imread(test_img) # use the test image from previous cell\n",
    "image = mpimg.imread(test_img_path)\n",
    "undistort_img = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "# global parameters\n",
    "corners = [(576,460), (705,460), (1102, 705),(180, 705)]\n",
    "src = np.float32([corners[0], corners[1], corners[2], corners[3]])\n",
    "dst = np.float32([[320,0],[960, 0],[960, 720],[320, 720]])\n",
    "# result, result_color = pipeline(undistort_img)\n",
    "\n",
    "def perspective_warp(img):\n",
    "    # Grab the image shape\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "    # Given src and dst points, calculate the perspective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    # Warp the image using OpenCV warpPerspective()\n",
    "    warped = cv2.warpPerspective(img, M, img_size)\n",
    "\n",
    "    # Return the resulting image and matrix\n",
    "    return warped\n",
    "\n",
    "def erode_image(img, k_size=(3,3)):\n",
    "    kernel = np.ones(k_size,np.uint8)\n",
    "    erosion = cv2.erode(img,kernel,iterations = 1)\n",
    "    return erosion\n",
    "\n",
    "def draw_polyline(img, pts):\n",
    "    # Draw a polygon\n",
    "    pts = pts.reshape((-1,1,2))\n",
    "    pts = np.int32(pts) # convert float to int to avoid errors\n",
    "    cv2.polylines(img,[pts],True,(255,0,0), 2)\n",
    "    return img\n",
    "\n",
    "\n",
    "# # test\n",
    "# birds_eye = perspective_warp(result)\n",
    "# eroded_birds_eye = erode_image(birds_eye)\n",
    "\n",
    "# # Plot the result\n",
    "# #f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "# #f.tight_layout()\n",
    "\n",
    "# ax1.imshow(result, cmap='gray')\n",
    "# ax1.set_title('Binary Image', fontsize=40)\n",
    "\n",
    "# ax2.imshow(birds_eye, cmap='gray')\n",
    "# ax2.set_title('Binary Birds Eye View', fontsize=40)\n",
    "# plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "# # save the result to disk\n",
    "# io.imsave('./output_images/birds_eye.jpg', img_as_uint(birds_eye))\n",
    "\n",
    "# original test image!!\n",
    "# plot the image with warp\n",
    "f, (ax3, ax4) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax3.imshow(undistort_img)\n",
    "ax3.set_title('Original test Image', fontsize=40)\n",
    "\n",
    "warped_image = perspective_warp(undistort_img)\n",
    "warped_cv2_image = cv2.cvtColor(warped_image, cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite('./warped_image.jpg', warped_cv2_image)\n",
    "ax4.imshow(warped_image)\n",
    "ax4.set_title('Birds Eye View', fontsize=40)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "# # save the result to disk\n",
    "# io.imsave('./output_images/warped_image.jpg', img_as_uint(warped_image))\n",
    "\n",
    "# # plot the binary image with erosion\n",
    "# #f, (ax5, ax6) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "# #f.tight_layout()\n",
    "\n",
    "# ax5.imshow(birds_eye, cmap='gray')\n",
    "# ax5.set_title('Binary Birds Eye View', fontsize=40)\n",
    "\n",
    "# ax6.imshow(eroded_birds_eye, cmap='gray')\n",
    "# ax6.set_title('Eroded Binary Birds Eye View', fontsize=40)\n",
    "# plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "# # plot polyline to verify lines are parallel\n",
    "# #f, (ax7, ax8) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "# #f.tight_layout()\n",
    "\n",
    "# image = mpimg.imread('./test_images/straight_lines1.jpg') # use the test image with straight lines\n",
    "# undistorted_straight_line_img = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "# polyline_img = draw_polyline(undistorted_straight_line_img, src)\n",
    "# ax7.imshow(polyline_img)\n",
    "# ax7.set_title('Undistorted image with source points drawn', fontsize=40)\n",
    "# io.imsave('./output_images/undistorted_img_w_source_pts.jpg', img_as_uint(undistorted_straight_line_img))\n",
    "\n",
    "# warped_polyline_img = perspective_warp(polyline_img)\n",
    "# ax8.imshow(warped_polyline_img)\n",
    "# ax8.set_title('Warped result with dest. point drawn', fontsize=40)\n",
    "# plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "# io.imsave('./output_images/warped_result_w_dest_pts.jpg', img_as_uint(warped_polyline_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Video processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global variables\n",
    "# first_image = True\n",
    "# left_line = Line()\n",
    "# right_line = Line()\n",
    "# line_check_fault_counter = 0\n",
    "def process_image(image, debug_info = False):\n",
    "    global first_image\n",
    "#     global left_line, right_line\n",
    "#     global line_check_fault_counter\n",
    "    # undistort the image\n",
    "    undistort_img = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    \n",
    "    # feed the image to the color/gradient thresholding pipeline\n",
    "    # to create a binary image\n",
    "#     result, result_color = pipeline(undistort_img)\n",
    "    \n",
    "    # unwarp the binary image to a birds eye view\n",
    "    birds_eye = perspective_warp(undistort_img)\n",
    "    \n",
    "    # Fit a second order polynomial for left and right line\n",
    "#    l_line, r_line, last_l_line, last_r_line = polynomial_fit(birds_eye, left_line, right_line, \n",
    "#                                                              line_check_fault_counter, fault_thres = 5)\n",
    "#    info = None\n",
    "        \n",
    "    # sanity check for lines\n",
    "#    if ((line_check(l_line, r_line) is True) or (first_image is True)):\n",
    "\n",
    "#         first_image = False\n",
    "#         # save data from this frame for the next loop\n",
    "#         left_line = l_line\n",
    "#         right_line = r_line\n",
    "                   \n",
    "        # Warp the lane boundary back to the original image, with the best fitted x values\n",
    "#         result = map_lane(undistort_img, birds_eye, \n",
    "#                           left_line.current_fit, right_line.current_fit,\n",
    "#                           left_line.bestx, right_line.bestx,\n",
    "#                           use_bestfit = True)\n",
    "        \n",
    "        # measure car's offset from the lane center\n",
    "#         offset, side = measure_offset_from_lane_center(birds_eye, left_line.current_fit, right_line.current_fit)\n",
    "#         # clear the counter\n",
    "#         line_check_fault_counter = 0\n",
    "#     else:\n",
    "#         # save data from this frame for the next loop\n",
    "#         left_line = last_l_line\n",
    "#         right_line = last_r_line\n",
    "               \n",
    "#         # Warp the lane boundary back to the original image, with the best fitted x values\n",
    "#         result = map_lane(undistort_img, birds_eye, \n",
    "#                           left_line.current_fit, right_line.current_fit,\n",
    "#                           left_line.bestx, right_line.bestx,\n",
    "#                           use_bestfit = True)\n",
    "        \n",
    "#         # measure car's offset from the lane center\n",
    "#         offset, side = measure_offset_from_lane_center(birds_eye, left_line.current_fit, right_line.current_fit)\n",
    "#         # line check fails, so increment the fault counter\n",
    "#         line_check_fault_counter += 1 \n",
    "\n",
    "#     # display curvature and car offset from center on the screen\n",
    "#     info = 'Vehicle is ' + str(offset) + 'm ' + side + ' of center'\n",
    "#     display_car_offset(result, info)     \n",
    "#     display_text(result, left_line, right_line)\n",
    "  \n",
    "#     if (debug_info is True):\n",
    "#         display_fault_counter(result, str(line_check_fault_counter), \n",
    "#                               str(fault_similar_curve), \n",
    "#                               str(fault_curve_ratio), \n",
    "#                               str(fault_curve_distance),\n",
    "#                               str(use_window))\n",
    "    return birds_eye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Test the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "project_output = 'finished_project_video.mp4'\n",
    "input_clip = VideoFileClip(\"project_video.mp4\")\n",
    "output_clip = input_clip.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time output_clip.write_videofile(project_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
